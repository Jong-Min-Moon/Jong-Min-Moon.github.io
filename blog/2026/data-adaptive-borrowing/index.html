<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Paper review: Improving randomized controlled trial analysis via data-adaptive borrowing | Jongmin Mun</title> <meta name="author" content="Jongmin Mun"> <meta name="description" content="A deep dive into how machine learning and adaptive lasso can enhance RCTs by selectively borrowing information from external controls."> <meta name="keywords" content="Jongmin Mun, USC"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?v=1771617130"> <link rel="canonical" href="https://jong-min-moon.github.io/blog/2026/data-adaptive-borrowing/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "Paper review: Improving randomized controlled trial analysis via data-adaptive borrowing",
      "description": "A deep dive into how machine learning and adaptive lasso can enhance RCTs by selectively borrowing information from external controls.",
      "published": "February 20, 2026",
      "authors": [
        {
          "author": "Jong Min Moon",
          "authorURL": "https://github.com/Jong-Min-Moon",
          "affiliations": [
            {
              "name": "USC Marshall",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Jongmin </span>Mun</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/coursework/">Coursework</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Posts<span class="sr-only">(current)</span></a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Paper review: Improving randomized controlled trial analysis via data-adaptive borrowing</h1> <p>A deep dive into how machine learning and adaptive lasso can enhance RCTs by selectively borrowing information from external controls.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#core-assumptions">Core Assumptions</a></div> <div><a href="#the-detection-mechanism">The Detection Mechanism</a></div> <div><a href="#practical-implementation">Practical Implementation</a></div> </nav> </d-contents> <h2 id="core-assumptions">Core Assumptions</h2> <p><strong>Assumption 2 (External control compatibility).</strong> Suppose that (i) $E{Y(0) \mid X = x, R = 0} = E{Y (0) \mid X = x, R = 1}$ and…</p> <h2 id="the-detection-mechanism">The Detection Mechanism</h2> <p>The adaptive lasso penalty detects incomparable external controls by recasting the challenge of identifying compatible subjects as a model selection problem based on individual bias. Here is how the detection mechanism works:</p> <ul> <li> <strong>Defining the Bias Parameter:</strong> For each external control subject, a specific bias parameter ($b_{i,0}$) is introduced. This parameter measures the difference in the expected outcome between the external control subject and a concurrent trial control subject, given their baseline covariates. An external subject is considered comparable if their bias is exactly zero ($b_{i,0} = 0$) and incomparable if it is non-zero.</li> <li> <strong>Initial Estimation:</strong> The framework first uses machine learning models to calculate an initial, consistent estimate of this bias ($\hat{b}_{i}$) for every single external subject.</li> <li> <table> <tbody> <tr> <td> <strong>Applying the Penalty:</strong> A refined bias estimator ($\tilde{b}$) is then computed using penalized estimation. The adaptive lasso penalty term applied to each subject is proportional to $</td> <td>b_{i}</td> <td>/</td> <td>\hat{b}_{i}</td> <td>^{\nu}$.</td> </tr> </tbody> </table> </li> <li> <strong>The Shrinkage Mechanism:</strong> Because the initial bias estimate ($\hat{b}<em>{i}$) acts as the denominator in the penalty term, it dictates the severity of the penalty. If an external subject is truly comparable, their initial bias estimate will be close to zero, which forces the associated penalty to become exceedingly large. This massive penalty shrinks the subject’s final, refined bias estimate ($\tilde{b}</em>{i}$) exactly to zero.</li> <li> <strong>Selective Borrowing:</strong> Once the penalized estimation is complete, the framework looks at the refined bias estimates. Any external subject whose refined bias is exactly zero ($\tilde{b}_{i} = 0$) is grouped into a comparable subset ($\tilde{\mathcal{A}}$) and retained for the trial analysis, while anyone with a non-zero bias is permanently excluded.</li> </ul> <p>By using this penalty, the framework achieves “selection consistency” (Lemma 1). This means that as long as the initial estimator is high quality and the tuning parameters are chosen properly, the adaptive lasso will consistently and reliably pinpoint the zero-bias subjects, naturally filtering out incomparable external controls that could otherwise skew the trial’s results.</p> <h2 id="practical-implementation">Practical Implementation</h2> <p>To learn the exact value of the bias parameter for each external control subject, the framework uses a two-step process involving machine learning predictions followed by a penalized optimization:</p> <ol> <li> <strong>Defining the True Bias:</strong> The true subject-level bias, $b_{i,0}$, is defined mathematically as the difference between the expected conditional outcome for an external control subject ($\mu_{0,E}(X_{i})$) and a concurrent trial control subject ($\mu_{0}(X_{i})$), which is expressed as $b_{i,0} = \mu_{0,E}(X_{i}) - \mu_{0}(X_{i})$.</li> <li> <strong>Calculating an Initial Estimate:</strong> An initial, unpenalized estimator, $\hat{b}<em>{i}$, is constructed by calculating the difference between the estimated outcome means for both groups: $\hat{b}</em>{i} = \hat{\mu}<em>{0,E}(X</em>{i}) - \hat{\mu}<em>{0}(X</em>{i})$. In practice, these conditional outcome means ($\hat{\mu}<em>{0,E}$ and $\hat{\mu}</em>{0}$) are estimated using off-the-shelf machine learning algorithms that possess guaranteed convergence rates.</li> <li> <strong>Applying the Adaptive Lasso Penalty:</strong> Finally, a refined bias estimator, $\tilde{b}$, is computed by solving a penalized least-squares optimization problem. The framework finds the vector of biases $b$ that minimizes the following equation:</li> </ol> \[\tilde{b} = \text{argmin}_{b} \{ (\hat{b}-b)^{T} \hat{\Sigma}_{b}^{-1} (\hat{b}-b) + \lambda_{N} \sum_{i \in E} p(|b_{i}|) \}\] <h3 id="breaking-down-the-components">Breaking down the components:</h3> <ul> <li>$\hat{\Sigma}_{b}$ is the estimated variance of the initial bias estimator $\hat{b}$.</li> <li> <table> <tbody> <tr> <td>$p(</td> <td>b_{i}</td> <td>)$ is the adaptive lasso penalty term applied to each subject, which is defined as $</td> <td>b_{i}</td> <td>/</td> <td>\hat{b}_{i}</td> <td>^{\nu}$.</td> </tr> </tbody> </table> </li> <li>$\lambda_{N}$ and $\nu$ are two tuning parameters that dictate the strength of the penalty; they are selected by minimizing the mean square error using cross-validation.</li> </ul> <table> <tbody> <tr> <td>Because the initial estimate $\hat{b}_{i}$ acts as the denominator in the penalty term $p(</td> <td>b_{i}</td> <td>)$, subjects who are truly comparable (and thus have an initial bias estimate close to zero) will receive an exceedingly large penalty. This dynamic successfully shrinks their final refined bias estimate ($\tilde{b}_{i}$) to exactly zero, allowing the framework to pinpoint and select them for the trial.</td> </tr> </tbody> </table> <p>cenrla limit diffusion</p> <p>fluid market sie lambda t</p> <p>precious setting: lambda and n together goes to infinty static price approach (dynamic pricing is not need in seminal dynamic rpciing paper) uses CLT iterative reoptimization heuristic the core logic is even though we use CLT, we dont need large number actually</p> <p>this talk focuses on large market regime core: same CLT small number argument</p> <p>the core message: what matter is the ratio. not which one is fixed</p> <p>plot: the optial policy in large market regime is not the static policy (high price w</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2026 Jongmin Mun. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>