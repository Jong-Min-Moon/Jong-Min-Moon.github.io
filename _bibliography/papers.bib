
@article{namgung_sex_2024,
	title = {Sex differences in autism spectrum disorder using class imbalance adjusted functional connectivity},
	volume = {304},
	issn = {1053-8119},
	html = {https://doi.org/10.1016/j.neuroimage.2024.120956},
abstract=  {
Functional connectivity refers to the correlations between neural signal time series across different brain regions, in contrast to the physical (structural) connections between them. We are interested in understanding how autism causally affects functional connectivity, and whether this effect differs between sexes. From a statistical perspective, this problem corresponds to estimating heterogeneous treatment effects (HTEs). Because autism spectrum disorder (ASD) is diagnosed more frequently in males than in females, the number of female participants in the autism group is substantially smaller. As a result, female samples contribute less to the HTE estimation algorithm, leading to potentially unstable estimates for females. To address this subgroup imbalance, we employ oversampling using a cluster-aware generative model. The augmented data increase the representation of female samples in the HTE estimation process, thereby improving the stability and reliability of HTE estimates for females. Our results reveal that several brain regions exhibit significant HTEs that were not detectable prior to oversampling. Furthermore, we demonstrate that the identified HTEs are not random noise but have clear biological meaning: they are strongly associated with higher-order cognitive control functions, rather than lower-level sensory processing, and are linked to autism-related genes.
},
urldate = {2024-12-15},
journal = {NeuroImage},
author = {Namgung, Jong Young and Mun, Jongmin and Park, Yeongjun and Kim, Jaeoh and 
Park, Bo-yong
},
	month = dec,
	year = {2024},
	keywords = {Autism spectrum disorder, Class imbalance, Functional gradient, Gaussian mixture model, Oversampling, Sex difference},
	pages = {120956},
	category = "class imbalance, computational neuroscience, causal inference",
		preview={neuroimage.png},
		note="Preliminary version  presented at the
		2024 International Conference of the IEEE Engineering in Medicine and Biology Society"
}


@article{nam_prediction_2024,
	title = {Prediction of forest fire risk for artillery military training using weighted support vector machine for imbalanced data},
	volume = {41},
	issn = {1432-1343},
	html = {https://doi.org/10.1007/s00357-024-09467-1},
	abstract=  {
  Artillery training inherently poses wildfire risks. Predictive modeling of these wildfires faces two key challenges: the scarcity of wildfire cases and the limited granularity of meteorological data during training. We address the first challenge by augmenting the data using a Gaussian mixture generative model and adjusting the loss function of a support vector machine. To tackle the second challenge, we integrate the Republic of Korea Army (ROKA) dataset with the Korea Meteorological Administration database. Our resulting model achieves a 99% improvement in balanced classification metrics compared to previous models.
  },
  language = {en},
	number = {1},
	urldate = {2024-06-09},
	journal = {Journal of Classification},
	author = {Nam, Ji Hyun and Mun, Jongmin and Jo, Seongil and Kim, Jaeoh},
	month = mar,
	year = {2024},
	pages = {170--189},
	category = {class imbalance},
	preview={forest_fire.png}
}
@article{munOfflineDynamicPricing2025,
  title = {Offline Dynamic Pricing under Covariate Shift and Local Differential Privacy via Twofold Pessimism},
  journal = {{{NeurIPS}} 2025 {{Workshop MLxOR}}},
  author = {Mun, Jongmin and Xu, Xiaocong and Fan, Yingying},
  year = 2025,
  month = nov,
  category = "differential privacy, nonparametric statistics, reinforcement learning/bandits, causal inference",
  abstract = {We study offline policy learning under market shift and privacy protection. Motivated by high-stakes pricing for new products, where price experimentation is infeasible, we leverage historical transaction data from heterogeneous, privacy-protected sources. We model heterogeneity via a covariate shift assumption, where the relationship between price, features, and revenue remains invariant, and privacy through local differential privacy (LDP), where each data point is perturbed before use. Viewing both as distributional shifts, we design a policy learning algorithm grounded in the pessimism principle of offline reinforcement learning. Without privacy, our predict-then-optimize approach constructs a pessimistic revenue predictor and optimizes it to set prices, achieving minimax-optimal decision error. Under LDP, we apply the Laplace mechanism and adapt the pessimistic revenue predictor to account for additional uncertainty introduced by privacy noise. The resulting doubly pessimistic objective is then optimized to determine the final pricing policy.},
  html = {https://openreview.net/pdf?id=ZL748l6oQG}
}


@article{mun_weighted_2025,
	title = {Weighted support vector machine for extremely imbalanced data},
	volume = {203},
	issn = {0167-9473},
html = {https://doi.org/10.1016/j.csda.2024.108078},
	abstract=  {
  Data augmentation and loss function adjustments are two common techniques for imbalanced classification.
  In cases of extreme class imbalance, it is often standard practice to combine these two approaches.
  However, determining the optimal oversampling ratio and the degree of asymmetry in the loss function typically relies on heuristics.
  We further consider the scenario where the minority class consists of subgroups and
  propose a straightforward method for combining data augmentation and loss function adjustments.
  This method serves as a sample-based approximation of the population-level asymptotically Bayes optimal oracle procedure.
  },
  urldate = {2024-11-10},
	journal = {Computational Statistics \& Data Analysis},
	author = {Mun, Jongmin and Bang, Sungwan and Kim, Jaeoh},
	month = mar,
	  selected = {true},
	year = {2025},
	pages = {108078},
    paper = {https://doi.org/10.1016/j.csda.2024.108078},
	category = {Class Imbalance},
	preview={wsvm.png}
}

@article{park_-vivo_2024,
	title = {In-vivo integration of soft neural probes through high-resolution printing of liquid electronics on the cranium},
	volume = {15},
	copyright = {2024 The Author(s)},
	issn = {2041-1723},
	html = {https://doi.org/10.1038/s41467-024-45768-0},
	abstract=  {
To enable high-quality neural recordings in freely moving animals, our materials science team developed a liquid metalâ€“based neural probe that can be directly printed onto the brain, along with elastic electronic circuits. To validate the fidelity of the signals recorded by this neural probe, we statistically assessed the long-term stability of signal clustering and examined the correlations between micro-scale neuronal activity and macro-level brain dynamics during mouse behavioral experiments involving visual and motor stimuli.
  },
	urldate = {2024-06-09},
	journal = {Nature Communications},
	author = {Park, Young-Geun and Kwon, Yong Won and Koh, Chin Su and Kim, Enji and Lee, Dong Ha and Kim, Sumin and Mun, Jongmin and Hong, Yeon-Mi and Lee, Sanghoon and Kim, Ju-Young and Lee, Jae-Hyun and Jung, Hyun Ho and Cheon, Jinwoo and Chang, Jin Woo and Park, Jang-Ung},
	month = feb,
	year = {2024},
	pages = {1772},
    category = {computational neuroscience},
	  selected = {true},
	preview={natcomm.png}
}



@article{mun_minimax_2024,
	title = {Minimax optimal two-sample testing under local differential privacy},
	url = {http://jmlr.org/papers/v26/24-2016.html},
	html = {http://jmlr.org/papers/v26/24-2016.html},
	abstract=  {Federated learning, where user data remains on local devices and only weight updates are transmitted, has become the industry standard for training neural networks on sensitive data. Federated analytics builds on this infrastructure, enabling data science insights without transmitting raw data. However, recent studies show that hijacking weight updates or data summaries can allow recovery of the original raw data. To address this privacy risk, we propose a private A/B testing method that transmits noisy data summaries within the federated learning framework. We begin with multinomial data, introducing private permutation tests using privacy mechanisms like the Laplace mechanism, discrete Laplace mechanism, and Google's RAPPOR mechanism. We extend our approach to continuous data using binning and analyze uniform separation rates under local differential privacy (LDP). Our tests rigorously control Type I error, satisfy LDP constraints, and achieve minimax separation rates, highlighting the inherent privacy-utility trade-offs in private testing.},
	urldate = {2025-11-14},
	author = {Mun, Jongmin and Kwak, Seungwoo and Kim, Ilmun},
	  volume = {26},
  number = {252},
  pages = {1--79},
	year = {2025},
	month = nov,
slides = {slide_ldp.pdf},
pythonpackage = {https://pypi.org/project/privateAB/},
	journal = {Journal of Machine Learning Research},
	  selected = {true},
	  category = "differential privacy, nonparametric statistics",
	  preview={ldp_minimax.png}
}

@article{mun_hybrid_2026,
	title = {Hybrid Partial Least Squares Regression with Multiple Functional and Scalar Predictors},
	preprint = {https://doi.org/10.48550/arXiv.2601.16364},
	abstract=  {Motivated by renal imaging studies that combine renogram curves with pharmacokinetic and demographic covariates, we propose Hybrid partial least squares (Hybrid PLS) for simultaneous supervised dimension reduction and regression in the presence of cross-modality correlations. The proposed approach embeds multiple functional and scalar predictors into a unified hybrid Hilbert space and rigorously extends the nonlinear iterative PLS (NIPALS) algorithm. This theoretical development is complemented by a sample-level algorithm that incorporates roughness penalties to control smoothness. By exploiting the rank-one structure of the resulting optimization problem, the algorithm admits a computationally efficient closed-form solution that requires solving only linear systems at each iteration. We establish fundamental geometric properties of the proposed framework, including orthogonality of the latent scores and PLS directions. Extensive numerical studies on synthetic data, together with an application to a renal imaging study, validate these theoretical results and demonstrate the method's ability to recover predictive structure under intermodal multicollinearity, yielding parsimonious low-dimensional representations.},
	urldate = {2026-01-25},
	publisher = {arXiv},
	author = {Mun, Jongmin and Jang, Jeong Hoon},
	rpackage = {https://github.com/Jong-Min-Moon/FShybridPLS},
	month = jan,
	year = {2026},
	journal = {arxiv preprint},
	  selected = {true},
	  category = {high-dimensional statistics}

}

@article{mun_clustering_2024,
	title = {Iterative Exploration-Driven Sparse SDP Clustering via Thompson Sampling},
	preprint = {https://jong-min.org/assets/pdf/sdp_clustering_preprint.pdf},
	abstract=  {This paper studies high-dimensional sparse clustering, a combinatorial NP-hard problem arising from the bilinear coupling between cluster assignment and feature selection. We analyze semidefinite programming (SDP) relaxations of 
$K$-means and establish minimax separation bounds, demonstrating that these relaxations are theoretically robust to feature over-selection: exact recovery is preserved even in the presence of non-informative features. Leveraging this robustness, we propose a block-coordinate ascent framework that alternates between SDP-based clustering and non-conservative feature selection. To address the tendency of deterministic greedy methods to become trapped in local optima, we formulate the feature selection step as a Thompson sampling bandit problem. This approach introduces adaptive memory by aggregating historical variable-selection outcomes into posterior distributions, and selects features via posterior sampling, enabling stochastic exploration that promotes the inclusion of underexplored features and facilitates escape from local maxima. We establish conditions for consistent variable selection and exact clustering recovery, and extend the method to settings with unknown covariance through a scalable, inverse-free estimation procedure. Numerical experiments demonstrate that the proposed memory-driven approach consistently outperforms state-of-the-art sparse clustering methods.},
	urldate = {2025-05-26},
	publisher = {arXiv},
	author = {Mun, Jongmin and Dubey, Paromita   and Fan, Yingying},
	month = may,
slides = {slide_sdp.pdf},
	year = {2025},
	journal = {arxiv preprint},
	  selected = {true},
	  category = "high-dimensional statistics, reinforcement learning/bandits"
}
