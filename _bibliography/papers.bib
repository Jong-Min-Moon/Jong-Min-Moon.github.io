---
---



}

@article{namgung_sex_2024,
	title = {Sex differences in autism spectrum disorder using class imbalance adjusted functional connectivity},
	volume = {304},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811924004531},
	doi = {10.1016/j.neuroimage.2024.120956},
abstract=  {
Functional connectivity refers to the correlations between neural signal time series across different brain regions, in contrast to the physical (structural) connections between them. We are interested in understanding how autism causally affects functional connectivity, and whether this effect differs between sexes. From a statistical perspective, this problem corresponds to estimating heterogeneous treatment effects (HTEs). Because autism spectrum disorder (ASD) is diagnosed more frequently in males than in females, the number of female participants in the autism group is substantially smaller. As a result, female samples contribute less to the HTE estimation algorithm, leading to potentially unstable estimates for females. To address this subgroup imbalance, we employ oversampling using a cluster-aware generative model. The augmented data increase the representation of female samples in the HTE estimation process, thereby improving the stability and reliability of HTE estimates for females. Our results reveal that several brain regions exhibit significant HTEs that were not detectable prior to oversampling. Furthermore, we demonstrate that the identified HTEs are not random noise but have clear biological meaning: they are strongly associated with higher-order cognitive control functions, rather than lower-level sensory processing, and are linked to autism-related genes.
},
urldate = {2024-12-15},
journal = {NeuroImage},
author = {Namgung, Jong Young and Mun, Jongmin and Park, Yeongjun and Kim, Jaeoh and 
Park, Bo-yong
},
	month = dec,
	year = {2024},
	keywords = {Autism spectrum disorder, Class imbalance, Functional gradient, Gaussian mixture model, Oversampling, Sex difference},
	pages = {120956},
	category = {Imbalance},
		preview={neuroimage.png},
		note="Preliminary version  presented at the
		2024 International Conference of the IEEE Engineering in Medicine and Biology Society"
}


@article{nam_prediction_2024,
	title = {Prediction of forest fire risk for artillery military training using weighted support vector machine for imbalanced data},
	volume = {41},
	issn = {1432-1343},
	url = {https://doi.org/10.1007/s00357-024-09467-1},
	doi = {10.1007/s00357-024-09467-1},
	abstract=  {
  Artillery training inherently poses wildfire risks. Predictive modeling of these wildfires faces two key challenges: the scarcity of wildfire cases and the limited granularity of meteorological data during training. We address the first challenge by augmenting the data using a Gaussian mixture generative model and adjusting the loss function of a support vector machine. To tackle the second challenge, we integrate the Republic of Korea Army (ROKA) dataset with the Korea Meteorological Administration database. Our resulting model achieves a 99% improvement in balanced classification metrics compared to previous models.
  },
  language = {en},
	number = {1},
	urldate = {2024-06-09},
	journal = {Journal of Classification},
	author = {Nam, Ji Hyun and Mun, Jongmin and Jo, Seongil and Kim, Jaeoh},
	month = mar,
	year = {2024},
	pages = {170--189},
	category = {Imbalance},
	preview={forest_fire.png}
}


@article{mun_weighted_2025,
	title = {Weighted support vector machine for extremely imbalanced data},
	volume = {203},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947324001622},
	doi = {10.1016/j.csda.2024.108078},
	abstract=  {
  Data augmentation and loss function adjustments are two common techniques for imbalanced classification.
  In cases of extreme class imbalance, it is often standard practice to combine these two approaches.
  However, determining the optimal oversampling ratio and the degree of asymmetry in the loss function typically relies on heuristics.
  We further consider the scenario where the minority class consists of subgroups and
  propose a straightforward method for combining data augmentation and loss function adjustments.
  This method serves as a sample-based approximation of the population-level asymptotically Bayes optimal oracle procedure.
  },
  urldate = {2024-11-10},
	journal = {Computational Statistics \& Data Analysis},
	author = {Mun, Jongmin and Bang, Sungwan and Kim, Jaeoh},
	month = mar,
	  selected = {true},
	year = {2025},
	pages = {108078},
    paper = {https://doi.org/10.1016/j.csda.2024.108078},
	category = {Imbalance},
	preview={wsvm.png}
}

@article{park_-vivo_2024,
	title = {In-vivo integration of soft neural probes through high-resolution printing of liquid electronics on the cranium},
	volume = {15},
	copyright = {2024 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-024-45768-0},
	doi = {10.1038/s41467-024-45768-0},
	abstract=  {
To enable high-quality neural recordings in freely moving animals, our materials science team developed a liquid metalâ€“based neural probe that can be directly printed onto the brain, along with elastic electronic circuits. To validate the fidelity of the signals recorded by this neural probe, we statistically assessed the long-term stability of signal clustering and examined the correlations between micro-scale neuronal activity and macro-level brain dynamics during mouse behavioral experiments involving visual and motor stimuli.
  },
	urldate = {2024-06-09},
	journal = {Nature Communications},
	author = {Park, Young-Geun and Kwon, Yong Won and Koh, Chin Su and Kim, Enji and Lee, Dong Ha and Kim, Sumin and Mun, Jongmin and Hong, Yeon-Mi and Lee, Sanghoon and Kim, Ju-Young and Lee, Jae-Hyun and Jung, Hyun Ho and Cheon, Jinwoo and Chang, Jin Woo and Park, Jang-Ung},
	month = feb,
	year = {2024},
	pages = {1772},
  paper = {https://doi.org/10.1038/s41467-024-45768-0},
    category = {Brain},
	  selected = {true},
	preview={natcomm.png}
}



@article{mun_minimax_2024,
	title = {Minimax optimal two-sample testing under local differential privacy},
	url = {http://jmlr.org/papers/v26/24-2016.html},
	entry = {http://jmlr.org/papers/v26/24-2016.html},
	abstract=  {We explore the trade-off between privacy and statistical utility in private two-sample testing under local differential privacy (LDP) for both multinomial and continuous data. We begin by addressing the multinomial case, where we introduce private permutation tests using practical privacy mechanisms such as Laplace, discrete Laplace, and Google's RAPPOR. We then extend our multinomial approach to continuous data via binning and study its uniform separation rates under LDP over H{\textbackslash}"older and Besov smoothness classes. The proposed tests for both discrete and continuous cases rigorously control the type I error for any finite sample size, strictly adhere to LDP constraints, and achieve minimax separation rates under LDP. The attained minimax rates reveal inherent privacy-utility trade-offs that are unavoidable in private testing. To address scenarios with unknown smoothness parameters in density testing, we propose an adaptive test based on a Bonferroni-type approach that ensures robust performance without prior knowledge of the smoothness parameters. We validate our theoretical findings with extensive numerical experiments and demonstrate the practical relevance and effectiveness of our proposed methods.},
	urldate = {2025-11-14},
	author = {Mun, Jongmin and Kwak, Seungwoo and Kim, Ilmun},
	  volume = {26},
  number = {252},
  pages = {1--79},
	year = {2025},
	journal = {Jounral of Machine Learning Research},
	  selected = {true},
	  category = {Privacy},
	  preview={ldp_minimax.png}
}

@article{mun_clustering_2024,
	title = {High-Dimensional Sparse Clustering via Iterative Semidefinite Programming Relaxed K-Means},
	url = {https://arxiv.org/abs/2505.20478},
	doi = {https://doi.org/10.48550/arXiv.2505.20478},
	abstract=  {We propose an iterative algorithm for clustering high-dimensional data, where the true signal lies in a much lower-dimensional space. Our method alternates between feature selection and clustering, without requiring precise estimation of sparse model parameters. Feature selection is performed by thresholding a rough estimate of the discriminative direction, while clustering is carried out via a semidefinite programming (SDP) relaxation of K-means. In the isotropic case, the algorithm is motivated by the minimax separation bound for exact recovery of cluster labels using varying sparse subsets of features. This bound highlights the critical role of variable selection in achieving exact recovery. We further extend the algorithm to settings with unknown sparse precision matrices, avoiding full model parameter estimation by computing only the minimally required quantities. Across a range of simulation settings, we find that the proposed iterative approach outperforms several state-of-the-art methods, especially in higher dimensions.},
	urldate = {2025-05-26},
	publisher = {arXiv},
	author = {Mun, Jongmin and Dubey, Paromita   and Fan, Yingying},
	month = may,
	year = {2025},
	journal = {arxiv preprint},
	  selected = {true},
	  category = {Clustering}
}
