<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Modern Statistical Inference | Jongmin Mun</title> <meta name="author" content="Jongmin Mun"> <meta name="description" content="Ph.D. level course on Modern Statistical Inference, focusing on high-dimensional settings and statistical learning theory."> <meta name="keywords" content="Jongmin Mun, USC"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?v=1772155723"> <link rel="canonical" href="https://jong-min-moon.github.io/coursework/dso-699/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Jongmin </span>Mun</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Study</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/coursework/">Coursework</a> <a class="dropdown-item" href="/study/papers/">Papers</a> </div> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Posts</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Modern Statistical Inference</h1> <p class="post-description">Ph.D. level course on Modern Statistical Inference, focusing on high-dimensional settings and statistical learning theory.</p> <div class="post-meta"> <span class="badge badge-secondary">Fall 2023</span> <span class="badge badge-info">Adel Javanmard</span> </div> </header> <article> <h2 id="course-description">Course Description</h2> <p>This is a Ph.D. level lecture course exposing students to modern ideas in statistical theory. While the traditional theory assumes that one has access to many observations (large sample size) and the number of variables (features) is fixed, in the modern big data era we are able to collect fine-grained information on each individual that allows us to fit feature-rich models. Our emphasis will be on statistical inference for such high-dimensional settings where there may be many or significantly more variables than observations. We will cover ideas to gauge reliability of statistical methods and the reproducibility of findings.</p> <p>As an example, suppose that you develop a machine learning system to make personalized predictions (such as risk score for a patient). Consider the following questions:</p> <ul> <li>How certain should we be about predictions made by your algorithm?</li> <li>How certain should we be about the discovered associations between the variables and the response? Are they statistically significant?</li> <li>How fair is your prediction with respect to minority subgroups in the data?</li> </ul> <p>This class will serve as a rapid introduction to current topics in statistical learning with a focus on theory and methodology. The course will cover:</p> <ul> <li>Testing problems in high dimensions: Bonferroni’s method, Fisher’s test, higher criticism</li> <li>Multiple testing problems: family-wise error rate (FWER), procedures for controlling FWER, false discovery rate (FDR), procedures for controlling FDR, online control of FDR</li> <li>Conformal prediction, conformalized quantile regression and its applications</li> <li>Conditional randomization test</li> <li>Gaussian Comparison inequalities: Slepian’s inequality, Gaussian interpolation, Gordon’s theorem</li> <li>Applications of Gaussian inequalities for analyzing statistical behavior of M-estimators</li> </ul> <h2 id="learning-objectives">Learning Objectives</h2> <p>Upon successful completion of this course, students will be able to:</p> <ul> <li>Speak comfortably about statistical significance, p-values, confidence intervals.</li> <li>Evaluate statistical inference for high-dimensional settings, where there may be many or significantly more variables than observations, to improve the reliability of statistical methods and the reproducibility of findings, including any discovered associations between the variables and the response.</li> <li>Describe and analyze various statistical tests and their applications: Bonferroni’s global test, Fisher’s test, chi-square test, higher criticism.</li> <li>Identify multiple testing problems: family-wise error rate (FWER), procedures for controlling FWER, false discovery rate (FDR), procedures for controlling FDR, online control of FDR.</li> <li>Explain conformal prediction, conformalized quantile regression and its applications.</li> <li>Perform conditional randomization test to properly account for confounding factors.</li> <li>Prove Gaussian Comparison inequalities: Slepian’s inequality, Gaussian Interpolation and Gordon’s theorem.</li> <li>Apply Gaussian inequalities to derive precise asymptotic characterization of the statistical behavior of M-estimators.</li> </ul> <h2 id="required-materials">Required Materials</h2> <p>We will not follow a text book, but as a PhD class, you are highly encouraged to consult outside sources to supplement your learning. The following references may be useful for background readings:</p> <ol> <li> <strong>Large-Scale Inference: Empirical Bayes Methods for Estimation, Testing, and Prediction</strong> by B. Efron, IMS Monographs.</li> <li> <strong>Testing Statistical Hypotheses</strong>, Third edition, E. L. Lehmann, Joseph P. Romano, Springer Science &amp; Business Media.</li> <li> <strong>High-dimensional probability: An introduction with applications in data science</strong>. Vol. 47. Vershynin, Roman. Cambridge university press, 2018.</li> </ol> </article> <h2 class="mt-4">Project Updates</h2> <ul class="post-list"> <li> <span class="post-meta">Nov 1, 2023</span> <h3> <a class="post-link" href="/blog/2023/fdr-control/"> FDR control: Storey's procedure </a> </h3> <p>Review of Storey's procedure for FDR control.</p> </li> </ul> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2026 Jongmin Mun. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>