<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Publications | Jongmin Mun</title> <meta name="author" content="Jongmin Mun"> <meta name="description" content="Personal website of Jongmin Mun. "> <meta name="keywords" content="Jongmin Mun, USC"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?v=1771792709"> <link rel="canonical" href="https://jong-min-moon.github.io/publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Jongmin </span>Mun</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/coursework/">Coursework</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Posts</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <div class="project-filters"> <button class="filter-btn active" data-filter="all">All</button> <button class="filter-btn" data-filter="causal inference">causal inference</button> <button class="filter-btn" data-filter="reinforcement learning/bandits">reinforcement learning/bandits</button> <button class="filter-btn" data-filter="computational neuroscience">computational neuroscience</button> <button class="filter-btn" data-filter="differential privacy">differential privacy</button> <button class="filter-btn" data-filter="nonparametric statistics">nonparametric statistics</button> <button class="filter-btn" data-filter="high-dimensional statistics">high-dimensional statistics</button> <button class="filter-btn" data-filter="class imbalance">class imbalance</button> </div> <div class="publications-list"> <ol class="bibliography"> <li> <div class="row grid-item" data-category='"high-dimensional statistics"'> <div class="col-sm-2 abbr"></div> <div id="mun_hybrid_2026" class="col-sm-8"> <div class="title">Hybrid Partial Least Squares Regression with Multiple Functional and Scalar Predictors</div> <div class="author"> Jongmin Mun, and Jeong Hoon Jang</div> <div class="periodical"> <em>arxiv preprint</em>, Jan 2026 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Summary</a> <a href="https://github.com/Jong-Min-Moon/FShybridPLS" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">R Package</a> <a href="https://doi.org/10.48550/arXiv.2601.16364" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Preprint</a> </div> <div class="abstract hidden"> <p>Motivated by renal imaging studies that combine renogram curves with pharmacokinetic and demographic covariates, we propose Hybrid partial least squares (Hybrid PLS) for simultaneous supervised dimension reduction and regression in the presence of cross-modality correlations. The proposed approach embeds multiple functional and scalar predictors into a unified hybrid Hilbert space and rigorously extends the nonlinear iterative PLS (NIPALS) algorithm. This theoretical development is complemented by a sample-level algorithm that incorporates roughness penalties to control smoothness. By exploiting the rank-one structure of the resulting optimization problem, the algorithm admits a computationally efficient closed-form solution that requires solving only linear systems at each iteration. We establish fundamental geometric properties of the proposed framework, including orthogonality of the latent scores and PLS directions. Extensive numerical studies on synthetic data, together with an application to a renal imaging study, validate these theoretical results and demonstrate the method’s ability to recover predictive structure under intermodal multicollinearity, yielding parsimonious low-dimensional representations.</p> </div> </div> </div> </li> <li> <div class="row grid-item" data-category='"differential privacy, nonparametric statistics, reinforcement learning/bandits, causal inference"'> <div class="col-sm-2 abbr"></div> <div id="munOfflineDynamicPricing2025" class="col-sm-8"> <div class="title">Offline Dynamic Pricing under Covariate Shift and Local Differential Privacy via Twofold Pessimism</div> <div class="author"> Jongmin Mun, Xiaocong Xu, and Yingying Fan</div> <div class="periodical"> <em>NeurIPS 2025 Workshop MLxOR</em>, Nov 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Summary</a> <a href="https://openreview.net/pdf?id=ZL748l6oQG" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Published Version</a> </div> <div class="abstract hidden"> <p>We study offline policy learning under market shift and privacy protection. Motivated by high-stakes pricing for new products, where price experimentation is infeasible, we leverage historical transaction data from heterogeneous, privacy-protected sources. We model heterogeneity via a covariate shift assumption, where the relationship between price, features, and revenue remains invariant, and privacy through local differential privacy (LDP), where each data point is perturbed before use. Viewing both as distributional shifts, we design a policy learning algorithm grounded in the pessimism principle of offline reinforcement learning. Without privacy, our predict-then-optimize approach constructs a pessimistic revenue predictor and optimizes it to set prices, achieving minimax-optimal decision error. Under LDP, we apply the Laplace mechanism and adapt the pessimistic revenue predictor to account for additional uncertainty introduced by privacy noise. The resulting doubly pessimistic objective is then optimized to determine the final pricing policy.</p> </div> </div> </div> </li> <li> <div class="row grid-item" data-category='"differential privacy, nonparametric statistics"'> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/ldp_minimax-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/ldp_minimax-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/ldp_minimax-1400.webp"></source> <img src="/assets/img/publication_preview/ldp_minimax.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="ldp_minimax.png" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mun_minimax_2024" class="col-sm-8"> <div class="title">Minimax optimal two-sample testing under local differential privacy</div> <div class="author"> Jongmin Mun, Seungwoo Kwak, and Ilmun Kim</div> <div class="periodical"> <em>Journal of Machine Learning Research</em>, Nov 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Summary</a> <a href="http://jmlr.org/papers/v26/24-2016.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Published Version</a> <a href="/assets/pdf/slide_ldp.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> <a href="https://pypi.org/project/privateAB/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Python Package</a> </div> <div class="abstract hidden"> <p>Federated learning, where user data remains on local devices and only weight updates are transmitted, has become the industry standard for training neural networks on sensitive data. Federated analytics builds on this infrastructure, enabling data science insights without transmitting raw data. However, recent studies show that hijacking weight updates or data summaries can allow recovery of the original raw data. To address this privacy risk, we propose a private A/B testing method that transmits noisy data summaries within the federated learning framework. We begin with multinomial data, introducing private permutation tests using privacy mechanisms like the Laplace mechanism, discrete Laplace mechanism, and Google’s RAPPOR mechanism. We extend our approach to continuous data using binning and analyze uniform separation rates under local differential privacy (LDP). Our tests rigorously control Type I error, satisfy LDP constraints, and achieve minimax separation rates, highlighting the inherent privacy-utility trade-offs in private testing.</p> </div> </div> </div> </li> <li> <div class="row grid-item" data-category='"high-dimensional statistics, reinforcement learning/bandits"'> <div class="col-sm-2 abbr"></div> <div id="mun_clustering_2024" class="col-sm-8"> <div class="title">Iterative Exploration-Driven Sparse SDP Clustering via Thompson Sampling</div> <div class="author"> Jongmin Mun, Paromita Dubey, and Yingying Fan</div> <div class="periodical"> <em>arxiv preprint</em>, May 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Summary</a> <a href="/assets/pdf/slide_sdp.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> <a href="https://arxiv.org/pdf/2505.20478" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Preprint</a> </div> <div class="abstract hidden"> <p>This paper studies high-dimensional sparse clustering, a combinatorial NP-hard problem arising from the bilinear coupling between cluster assignment and feature selection. We analyze semidefinite programming (SDP) relaxations of K-means and establish minimax separation bounds, demonstrating that these relaxations are theoretically robust to feature over-selection: exact recovery is preserved even in the presence of non-informative features. Leveraging this robustness, we propose a block-coordinate ascent framework that alternates between SDP-based clustering and non-conservative feature selection. To address the tendency of deterministic greedy methods to become trapped in local optima, we formulate the feature selection step as a Thompson sampling bandit problem. This approach introduces adaptive memory by aggregating historical variable-selection outcomes into posterior distributions, and selects features via posterior sampling, enabling stochastic exploration that promotes the inclusion of underexplored features and facilitates escape from local maxima. We establish conditions for consistent variable selection and exact clustering recovery, and extend the method to settings with unknown covariance through a scalable, inverse-free estimation procedure. Numerical experiments demonstrate that the proposed memory-driven approach consistently outperforms state-of-the-art sparse clustering methods.</p> </div> </div> </div> </li> <li> <div class="row grid-item" data-category='"class imbalance"'> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/wsvm-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/wsvm-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/wsvm-1400.webp"></source> <img src="/assets/img/publication_preview/wsvm.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="wsvm.png" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mun_weighted_2025" class="col-sm-8"> <div class="title">Weighted support vector machine for extremely imbalanced data</div> <div class="author"> Jongmin Mun, Sungwan Bang, and Jaeoh Kim</div> <div class="periodical"> <em>Computational Statistics &amp; Data Analysis</em>, Mar 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Summary</a> <a href="https://doi.org/10.1016/j.csda.2024.108078" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Published Version</a> </div> <div class="abstract hidden"> <p> Data augmentation and loss function adjustments are two common techniques for imbalanced classification. In cases of extreme class imbalance, it is often standard practice to combine these two approaches. However, determining the optimal oversampling ratio and the degree of asymmetry in the loss function typically relies on heuristics. We further consider the scenario where the minority class consists of subgroups and propose a straightforward method for combining data augmentation and loss function adjustments. This method serves as a sample-based approximation of the population-level asymptotically Bayes optimal oracle procedure. </p> </div> </div> </div> </li> <li> <div class="row grid-item" data-category='"class imbalance, computational neuroscience, causal inference"'> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/neuroimage-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/neuroimage-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/neuroimage-1400.webp"></source> <img src="/assets/img/publication_preview/neuroimage.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="neuroimage.png" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="namgung_sex_2024" class="col-sm-8"> <div class="title">Sex differences in autism spectrum disorder using class imbalance adjusted functional connectivity</div> <div class="author"> Jong Young Namgung, Jongmin Mun, Yeongjun Park, Jaeoh Kim, and Bo-yong Park</div> <div class="periodical"> <em>NeuroImage</em>, Dec 2024 </div> <div class="periodical"> Preliminary version presented at the 2024 International Conference of the IEEE Engineering in Medicine and Biology Society </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Summary</a> <a href="https://doi.org/10.1016/j.neuroimage.2024.120956" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Published Version</a> </div> <div class="abstract hidden"> <p> Functional connectivity refers to the correlations between neural signal time series across different brain regions, in contrast to the physical (structural) connections between them. We are interested in understanding how autism causally affects functional connectivity, and whether this effect differs between sexes. From a statistical perspective, this problem corresponds to estimating heterogeneous treatment effects (HTEs). Because autism spectrum disorder (ASD) is diagnosed more frequently in males than in females, the number of female participants in the autism group is substantially smaller. As a result, female samples contribute less to the HTE estimation algorithm, leading to potentially unstable estimates for females. To address this subgroup imbalance, we employ oversampling using a cluster-aware generative model. The augmented data increase the representation of female samples in the HTE estimation process, thereby improving the stability and reliability of HTE estimates for females. Our results reveal that several brain regions exhibit significant HTEs that were not detectable prior to oversampling. Furthermore, we demonstrate that the identified HTEs are not random noise but have clear biological meaning: they are strongly associated with higher-order cognitive control functions, rather than lower-level sensory processing, and are linked to autism-related genes. </p> </div> </div> </div> </li> <li> <div class="row grid-item" data-category='"class imbalance"'> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/forest_fire-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/forest_fire-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/forest_fire-1400.webp"></source> <img src="/assets/img/publication_preview/forest_fire.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="forest_fire.png" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="nam_prediction_2024" class="col-sm-8"> <div class="title">Prediction of forest fire risk for artillery military training using weighted support vector machine for imbalanced data</div> <div class="author"> Ji Hyun Nam, Jongmin Mun, Seongil Jo, and Jaeoh Kim</div> <div class="periodical"> <em>Journal of Classification</em>, Mar 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Summary</a> <a href="https://doi.org/10.1007/s00357-024-09467-1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Published Version</a> </div> <div class="abstract hidden"> <p> Artillery training inherently poses wildfire risks. Predictive modeling of these wildfires faces two key challenges: the scarcity of wildfire cases and the limited granularity of meteorological data during training. We address the first challenge by augmenting the data using a Gaussian mixture generative model and adjusting the loss function of a support vector machine. To tackle the second challenge, we integrate the Republic of Korea Army (ROKA) dataset with the Korea Meteorological Administration database. Our resulting model achieves a 99% improvement in balanced classification metrics compared to previous models. </p> </div> </div> </div> </li> <li> <div class="row grid-item" data-category='"computational neuroscience"'> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/natcomm-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/natcomm-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/natcomm-1400.webp"></source> <img src="/assets/img/publication_preview/natcomm.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="natcomm.png" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="park_-vivo_2024" class="col-sm-8"> <div class="title">In-vivo integration of soft neural probes through high-resolution printing of liquid electronics on the cranium</div> <div class="author"> Young-Geun Park, Yong Won Kwon, Chin Su Koh, Enji Kim, Dong Ha Lee, Sumin Kim, Jongmin Mun, Yeon-Mi Hong, Sanghoon Lee, Ju-Young Kim, Jae-Hyun Lee, Hyun Ho Jung, Jinwoo Cheon, Jin Woo Chang, and Jang-Ung Park</div> <div class="periodical"> <em>Nature Communications</em>, Feb 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Summary</a> <a href="https://doi.org/10.1038/s41467-024-45768-0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Published Version</a> </div> <div class="abstract hidden"> <p> To enable high-quality neural recordings in freely moving animals, our materials science team developed a liquid metal–based neural probe that can be directly printed onto the brain, along with elastic electronic circuits. To validate the fidelity of the signals recorded by this neural probe, we statistically assessed the long-term stability of signal clustering and examined the correlations between micro-scale neuronal activity and macro-level brain dynamics during mouse behavioral experiments involving visual and motor stimuli. </p> </div> </div> </div> </li> </ol> </div> </div> <script src="/assets/js/projects.js"></script> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2026 Jongmin Mun. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>